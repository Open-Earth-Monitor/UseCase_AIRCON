---
title: "Download EEA AQ Station Data"
author: "Johannes Heisig"
date: "`r Sys.Date()`"
format: 
  gfm: default
  html: 
    embed-resources: true
knitr:
  opts_knit:
    root.dir: "/mnt/cloud/wwu1/ec_bronze/_nogroup/ae78a1ca-a0e8-4e4e-8992-69c34947db65/UseCase_AIRCON"
---


```{r}
suppressPackageStartupMessages({
  library(dplyr)
  library(tidyr)
  library(sf)
  library(data.table)
})

source("R/functions.R")
```


# Download

Construct URLS like the [EEA discomap service](https://discomap.eea.europa.eu/map/fme/AirQualityExport.htm) that return links to all matching AQ station data CSV files. CSVs each contain stations from 1 country for 1 year and 1 pollutant. `generate_download_urls()` first generates a request, executes it, and writes all matching URLs to file. These can be picked up by `check_station_urls()` to get corresponding country, year, pollutant, and station ID for each entry. Data is finally retrieved with `download_station_data()`.

Download AQ data for 3 countries of interest and 4 pollutants of interest:

- Netherlands, Belgium, Luxembourg
- NO2, O3, PM10, PM2.5

```{r}
countries = c("LU")
pollutants = c(7,8,5,6001)
dl_file = "tests/test_download_urls.txt"

generate_download_urls(countries, pollutants, 2015, 2016, file = dl_file)
check_station_urls(dl_file)
files = download_station_data(dl_file, "tests/download")  

head(files)
```


# Pre-processing

Combine and filter data to become analysis-ready. Respective functions use lazy `data.table`-objects created with `dtplyr` to chain processing steps and execute the efficiently all at once.

**Quality filter:**

- which [validity classes](http://dd.eionet.europa.eu/vocabulary/aq/observationvalidity/view) should be included?
    - currently 1
- which [verification classes](http://dd.eionet.europa.eu/vocabulary/aq/observationverification/view) should be included?
    - currently 1 & 2
  
**Station filter:**

keep background stations from rural, urban, and suburban areas.
  
Wrangle downloaded CSVs to time series tables with a spatial reference.

1. read and combine files by pollutant
2. apply validation / verification flags

```{r}
station_meta = arrow::read_parquet("AQ_stations/EEA_stations_meta.parquet")

countries = c("LU")
no2 = read_pollutant_dt(files, pollutant = "NO2", countries = countries) |> filter_quality()
o3 = read_pollutant_dt(files, pollutant = "O3", countries = countries) |> filter_quality()
pm10 = read_pollutant_dt(files, pollutant = "PM10", countries = countries) |> filter_quality()
pm25 = read_pollutant_dt(files, pollutant = "PM2.5", countries = countries) |> filter_quality()
```

3. join tables to a single time series with measurements of multiple pollutants
4. add station meta data including locations

```{r}
pollutants = list(NO2=no2, O3=o3, PM2.5=pm25, PM10=pm10)
poll_table = join_pollutants(pollutants)

class(poll_table)
poll_table = as.data.table(poll_table)
class(poll_table)

summary(poll_table)
purrr::map(poll_table |> select(names(pollutants)), function(x) sum(!is.na(x))) |> unlist()
nrow(poll_table)

# Station properties
table(poll_table$AirQualityStationEoICode |> droplevels())
table(poll_table$StationArea)
table(poll_table$StationType)

arrow::write_parquet(poll_table, "tests/LU_hourly_2015-2016_gaps.parquet")
```

