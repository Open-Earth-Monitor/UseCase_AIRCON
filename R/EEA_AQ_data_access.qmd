---
title: "Download EEA AQ Station Data"
author: "Johannes Heisig"
date: "`r Sys.Date()`"
format: 
  html: default
  gfm: default
knitr:
  opts_knit:
    root.dir: "/mnt/cloud/wwu1/ec_bronze/_nogroup/ae78a1ca-a0e8-4e4e-8992-69c34947db65/UseCase_AIRCON"
---


```{r}
suppressPackageStartupMessages({
  library(dplyr)
  library(tidyr)
  library(sf)
})

source("R/functions.R")
```


# Download

Construct URLS like the [EEA discomap service](https://discomap.eea.europa.eu/map/fme/AirQualityExport.htm) that return links to all matching AQ station data CSV files. CSVs each contain stations from 1 country for 1 year and 1 pollutant. `generate_download_urls()` first generates a request, executes it, and writes all matching URLs to file. These can be picked up by `check_station_urls()` to get corresponding country, year, pollutant, and station ID for each entry. Data is finally retrieved with `download_station_data()`.

Download AQ data for 3 countries of interest and 4 pollutants of interest:

- Netherlands, Belgium, Luxembourg
- NO2, O3, PM10, PM2.5

```{r}
countries = c("LU")
pollutants = c(7,8,5,6001)
dl_file = "tests/test_download_urls.txt"

generate_download_urls(countries, pollutants, 2015, 2016, file = dl_file)
check_station_urls(dl_file)
files = download_station_data(dl_file, "tests/download")  

head(files)
```


# Pre-processing

**Quality filter:**

- which [validity classes](http://dd.eionet.europa.eu/vocabulary/aq/observationvalidity/view) should be included?
    - currently 1
- which [verification classes](http://dd.eionet.europa.eu/vocabulary/aq/observationverification/view) should be included?
    - currently 1 & 2
  
**Station filter:**

keep background stations from rural, urban, and suburban areas.
  
Wrangle downloaded CSVs to time series tables with a spatial reference.

1. read and combine files by pollutant
2. apply validation / verification flags

```{r}
station_meta = arrow::read_parquet("AQ_stations/EEA_stations_meta.parquet")

countries = c("LU")
no2 = read_pollutant(files, countries = countries) |> filter_quality()
o3 = read_pollutant(files, pollutant = "O3", countries = countries) |> filter_quality()
pm10 = read_pollutant(files, pollutant = "PM10", countries = countries) |> filter_quality()
pm25 = read_pollutant(files, pollutant = "PM2.5", countries = countries) |> filter_quality()
```

3. join tables to a single time series with measurements of multiple pollutants
4. add station meta data including locations

```{r}
pollutants = list(no2, o3, pm25, pm10)
poll_table = join_pollutants(pollutants)

summary(poll_table)
purrr::map_vec(pollutants, nrow)
nrow(poll_table)

# Station properties
table(poll_table$AirQualityStationEoICode |> droplevels())
table(poll_table$StationArea)
table(poll_table$StationType)

arrow::write_parquet(poll_table, "AQ_data/LU_hourly_2015-2016_gaps.parquet")

# geoarrow::write_geoparquet(poll_table,  "AQ_data/NL_hourly_2015-2023_gaps_sf.parquet")
# cbind(st_drop_geometry(poll_table), 
#       st_coordinates(poll_table) |> as_tibble() |> setNames(c("Longitude","Latitude"))) |> 
#   arrow::write_parquet("AQ_data/NL_hourly_2015-2023_gaps.parquet")
```

